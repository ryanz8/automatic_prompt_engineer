{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Prompts with **Automatic Prompt Engineer** (APE)\n",
    "\n",
    "This notebook demonstrates how to use Automatic Prompt Engineer (APE) (arxiv link) to optimize prompts for text generation. In its simplest form, APE takes as input a dataset (a list of inputs and a list of outputs), a prompt template, and optimizes this prompt template so that it generates the outputs given the inputs.\n",
    "\n",
    "APE accomplishes this in two steps. First, it uses a language model to generate a set of candidate prompts. Then, it uses a prompt evaluation function to evaluate the quality of each candidate prompt. Finally, it returns the prompt with the highest evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define a simple dataset consisting of words and their antonyms.\n",
    "words = [\"sane\", \"direct\", \"informally\", \"unpopular\", \"subtractive\", \"nonresidential\",\n",
    "    \"inexact\", \"uptown\", \"incomparable\", \"powerful\", \"gaseous\", \"evenly\", \"formality\",\n",
    "    \"deliberately\", \"off\"]\n",
    "antonyms = [\"insane\", \"indirect\", \"formally\", \"popular\", \"additive\", \"residential\",\n",
    "    \"exact\", \"downtown\", \"comparable\", \"powerless\", \"solid\", \"unevenly\", \"informality\",\n",
    "    \"accidentally\", \"on\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to define the format of the prompt that we are using.\n",
    "\n",
    "eval_template = \\\n",
    "\"\"\"Instruction: [PROMPT]\n",
    "Input: [INPUT]\n",
    "Output: [OUTPUT]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prompts...\n",
      "[GPT_forward] Generating 50 completions, split into 1 batches of size 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model returned 50 prompts. Deduplicating...\n",
      "Deduplicated to 47 prompts.\n",
      "First 3 prompts: Output: dissempathy\n",
      "Output: convert\n",
      "Output: be learned\n",
      "\n",
      "Evaluating prompts... ea\n",
      "ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating prompts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 2446.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 47 47 !!!!!\n",
      "child Output: do Output: dissempathy\n",
      "mutate Output: do Output: dissempathy\n",
      "child Output: dissempathy Output: be short\n",
      "mutate Output: dissempathy Output: be short\n",
      "child Output: form the word at the bottom by adding the word Output: get confused\n",
      "mutate Output: form the word at the bottom by adding the word Output: get confused\n",
      "child Output: convert Output: generate an instruction\n",
      "mutate Output: convert Output: generate an instruction\n",
      "child Output: threct Output: die right person\n",
      "mutate Output: threct Output: die right person\n",
      "47 47 47 !!!!!\n",
      "child Output: dirsempathy Output: disect\n",
      "mutate Output: dirsempathy Output: disect\n",
      "child Output: get off the road Output: do\n",
      "mutate Output: get off the road Output: do\n",
      "child Output: do Output: an unread warning read\n",
      "mutate Output: do Output: an unread warning read\n",
      "child Output: help Output: get confused\n",
      "mutate Output: help Output: get confused\n",
      "child Output: help with the math Output: give instructions\n",
      "mutate Output: help with the math Output: give instructions\n",
      "47 47 47 !!!!!\n",
      "child Output: help with the math Output: do something else\n",
      "mutate Output: help with the math Output: do something else\n",
      "child Output: wiggle his arms out of the seat Output: incendiate\n",
      "mutate Output: wiggle his arms out of the seat Output: incendiate\n",
      "child Output: wiggle his arms out of the seat Output: get confused\n",
      "mutate Output: wiggle his arms out of the seat Output: get confused\n",
      "child Output: do Output: direct\n",
      "mutate Output: do Output: direct\n",
      "child Output: convert Output: construct\n",
      "mutate Output: convert Output: construct\n",
      "47 47 47 !!!!!\n",
      "child Output: wiggle his arms out of the seat Output: convert\n",
      "mutate Output: wiggle his arms out of the seat Output: convert\n",
      "child Output: help with the math Output: construct\n",
      "mutate Output: help with the math Output: construct\n",
      "child Output: find more ways to help the friend. Output: downtown\n",
      "mutate Output: find more ways to help the friend. Output: downtown\n",
      "child Output: an unread warning read Output: do\n",
      "mutate Output: an unread warning read Output: do\n",
      "child Output: convert Output: act as the instructor\n",
      "mutate Output: convert Output: actwas the instructor\n",
      "47 47 47 !!!!!\n",
      "child Output: direct Output: goofy\n",
      "mutate OuMput: direct Output: goofy\n",
      "child Output: goofy Output: be able to have a certain amount in the form of a letter of reference.\n",
      "mutate Output: goofy Output: be able to haje a certain amount in the form of a letter of reference.\n",
      "child Output: die right person Output: perform to use\n",
      "mutate Output: die right person Output: perform to use\n",
      "child Output: form the word at the bottom by adding the word Output: be written in alphabetical order\n",
      "mutate Output: form the word at the bottom by adding the word Output: be written in alphabetica; order\n",
      "child Output: die righthy Output: dissempat person\n",
      "mutate Output: die righthy Output: dissempat person\n",
      "evolution algorithm\n",
      "1111\n",
      "child Output: perfble to have a certain amount in the form of a letter of reference. Output: be aorm to use\n",
      "mutate Output: perfble to have a certain amount in the form of a letter of reference. Output: be aorm to use\n",
      "child Output: wiggle his arms out of the seat Output: do\n",
      "mutate Output: wiggle his arms out of the seat Output: do\n",
      "child Output: convert Output: get off the road\n",
      "mutate Output: convert Output: get off the road\n",
      "child Output: cause confusion Output: goofy\n",
      "mutate Output: cause confusion Output: goofy\n",
      "child Output: an unread warning read Output: do\n",
      "mutate Output: an unread warning read Output: do\n",
      "Finished evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, let's use APE to find prompts that generate antonyms for each word.\n",
    "from automatic_prompt_engineer import ape\n",
    "\n",
    "results = ape.eape(\n",
    "    dataset=(words, antonyms),\n",
    "    eval_template=eval_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with a prompt written by a human:\n",
    "\n",
    "\"*Write an antonym to the following word.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating prompts:   0%|                                                                                                                                                                 | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 !!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautomatic_prompt_engineer\u001b[39;00m \u001b[39mimport\u001b[39;00m ape\n\u001b[1;32m      3\u001b[0m manual_prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWrite an antonym to the following word.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m human_result \u001b[39m=\u001b[39m ape\u001b[39m.\u001b[39;49msimple_eval(\n\u001b[1;32m      6\u001b[0m     dataset\u001b[39m=\u001b[39;49m(words, antonyms),\n\u001b[1;32m      7\u001b[0m     eval_template\u001b[39m=\u001b[39;49meval_template,\n\u001b[1;32m      8\u001b[0m     prompts\u001b[39m=\u001b[39;49m[manual_prompt],\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/prompt_evo/automatic_prompt_engineer/automatic_prompt_engineer/ape.py:120\u001b[0m, in \u001b[0;36msimple_eval\u001b[0;34m(dataset, prompts, eval_template, demos_template, eval_model, num_samples)\u001b[0m\n\u001b[1;32m    117\u001b[0m conf[\u001b[39m'\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mbase_eval_config\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgpt_config\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eval_model\n\u001b[1;32m    118\u001b[0m conf[\u001b[39m'\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mnum_samples\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(dataset[\u001b[39m0\u001b[39m]), num_samples)\n\u001b[0;32m--> 120\u001b[0m res \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39;49mevalute_prompts(\n\u001b[1;32m    121\u001b[0m     prompts, eval_template, dataset, demos_template, dataset, conf[\u001b[39m'\u001b[39;49m\u001b[39mevaluation\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m'\u001b[39;49m], conf[\u001b[39m'\u001b[39;49m\u001b[39mevaluation\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/prompt_evo/automatic_prompt_engineer/automatic_prompt_engineer/evaluate.py:44\u001b[0m, in \u001b[0;36mevalute_prompts\u001b[0;34m(prompts, eval_template, eval_data, demos_template, few_shot_data, eval_method, config)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(eval_method)\n\u001b[1;32m     43\u001b[0m eval_method \u001b[39m=\u001b[39m get_eval_method(eval_method)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mreturn\u001b[39;00m eval_method(prompts, eval_template, eval_data, demos_template, few_shot_data, config)\n",
      "File \u001b[0;32m~/prompt_evo/automatic_prompt_engineer/automatic_prompt_engineer/evaluation/ea.py:36\u001b[0m, in \u001b[0;36mea_evaluator\u001b[0;34m(prompts, eval_template, eval_data, demos_template, few_shot_data, config)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m     35\u001b[0m     parent1,parent2\u001b[39m=\u001b[39m tournament_selection(prompts, ea_algo\u001b[39m.\u001b[39mscores, \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     child1,child2\u001b[39m=\u001b[39mcrossover_prompts(prompts[parent1], prompts[parent2], crossover_rate\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mchild\u001b[39m\u001b[39m'\u001b[39m,child1,child2)\n\u001b[1;32m     38\u001b[0m     child1\u001b[39m=\u001b[39mmutate_prompt(child1)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from automatic_prompt_engineer import ape\n",
    "\n",
    "manual_prompt = \"Write an antonym to the following word.\"\n",
    "\n",
    "human_result = ape.simple_eval(\n",
    "    dataset=(words, antonyms),\n",
    "    eval_template=eval_template,\n",
    "    prompts=[manual_prompt],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2afcb7a2e6fcb9490d448e607abf9226c3f7acca28baeea9bc24b456562037f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
